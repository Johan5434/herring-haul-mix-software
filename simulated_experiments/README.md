# Simulated Hauls Experiment Folder

This folder contains simulated herring hauls with **known population proportions** for testing and validating the PCA-based classification pipeline.

## Overview

The goal is to create synthetic hauls by mixing individuals from different populations at specified proportions, then use the pipeline to see how accurately it can recover the true population assignments.

## Quick Start

### One-Time Setup: Build Reference Model

```bash
# Build reference PCA model from empirical data (with QC filtering)
python build_reference_model.py --apply-qc

# This creates: reference_model/reference_pca.json
```

### Testing Simulated Hauls

```bash
# Test hauls 1-15
python test_simulated_hauls.py --hauls 1-15

# Test hauls 16-30
python test_simulated_hauls.py --hauls 16-30

# Test specific hauls
python test_simulated_hauls.py --hauls 1,5,10-20

# Results saved to: results/predictions_XXXX-XXXX_timestamp.csv
```

## Files Generated

### Core Output Files

**You only need these TWO files:**

1. **`simulated_hauls_metadata.txt`** (2 columns)
   - Format: `sample_id\thaul_id`
   - Maps each individual fish to its simulated haul
   - **Use this as the metadata file for the pipeline**
   - Each haul contains 30 individuals
   - Only 56 KB (not a separate VCF file)

**For validation:**

2. **`haul_proportions.txt`** (10 columns)
   - Format: `haul_id\tproportion_name\tAutumn_%\tNorth_%\tCentral_%\tSouth_%\tActual_A_count\tActual_N_count\tActual_C_count\tActual_S_count`
   - Documents the **true proportion** for each simulated haul
   - Shows both expected percentages and actual individual counts
   - Essential for evaluating pipeline accuracy

**Optional reference files:**

3. **`simulated_individuals_list.txt`**

   - Simple list of sample IDs used in hauls (one per line)
   - Reference only (not needed for pipeline)

4. **`qc_passed_individuals.txt`** (if QC filtering was run)
   - List of individuals that passed QC filters
   - Generated by `qc_before_simulation.py`
   - Reference only (used automatically during haul generation)

## Generated Hauls

**Total: 50 simulated hauls** (5 different proportions × 10 replicates each)

### Proportions

| Haul IDs       | Composition                        | Replicates |
| -------------- | ---------------------------------- | ---------- |
| haul_0001–0010 | 50% Autumn, 50% South              | 10         |
| haul_0011–0020 | 60% Autumn, 40% North              | 10         |
| haul_0021–0030 | 50% North, 50% Central             | 10         |
| haul_0031–0040 | 33% Autumn, 33% North, 33% Central | 10         |
| haul_0041–0050 | 25% each population (equal 4-way)  | 10         |

Each haul contains **30 individuals** sampled randomly from the specified populations.

## Complete Workflow

### Step 1: Generate Simulated Hauls (One-Time Setup)

#### 1a. (Optional) QC Filter Individuals

```bash
# Filter out outliers before haul generation
python qc_before_simulation.py
# → Creates qc_passed_individuals.txt (4,487 individuals)
```

#### 1b. Generate Hauls

```bash
# Creates simulated hauls from QC-passed individuals
python generate_simulated_hauls.py
# → Creates simulated_hauls_metadata.txt (80 hauls)
# → Creates haul_proportions.txt (ground truth)
```

### Step 2: Build Reference Model (One-Time Setup)

```bash
# Build PCA reference from empirical/original data
python build_reference_model.py --apply-qc

# Output: reference_model/reference_pca.json
```

**What it does:**

- Loads original VCF + metadata (all 4,647 empirical individuals)
- Applies QC filters (removes ~160 outliers)
- Builds individual PCA on empirical hauls
- Computes haul centroids (reference map)
- Saves model as JSON (human-readable)

**Do this ONCE** - the reference model is reused for all testing.

### Step 3: Test Simulated Hauls (Run Multiple Times)

```bash
# Test different batches of hauls
python test_simulated_hauls.py --hauls 1-15
python test_simulated_hauls.py --hauls 16-30
python test_simulated_hauls.py --hauls 31-45

# Each run creates: results/predictions_XXXX-XXXX_timestamp.csv
```

**What it does:**

- Loads reference model (pre-built PCA)
- Loads specified simulated hauls from metadata
- Projects simulated individuals to PCA space
- Computes haul centroids
- Classifies using rule-based method
- Compares predictions vs ground truth
- Outputs CSV with true/pred proportions + errors

**Run this many times** with different haul ranges to test all scenarios.

---

## Directory Structure

After running the full workflow:

```
simulated_experiments/
├── reference_model/              # Reference PCA (built once)
│   └── reference_pca.json        # PCA parameters + centroids
├── results/                      # Test results (one per run)
│   ├── predictions_0001-0015_20241211_143022.csv
│   ├── predictions_0016-0030_20241211_143145.csv
│   └── ...
├── simulated_hauls_metadata.txt  # Simulated haul assignments
├── haul_proportions.txt          # Ground truth proportions
├── qc_passed_individuals.txt     # QC-filtered individuals
├── build_reference_model.py      # Script: build reference
├── test_simulated_hauls.py       # Script: test hauls
├── generate_simulated_hauls.py   # Script: generate hauls
├── qc_before_simulation.py       # Script: QC filtering
└── README.md                     # This file
```

---

## QC Filtering (Optional)

To ensure simulated hauls use only high-quality individuals and maintain accurate ground truth proportions:

### Recommended Workflow: QC Before Haul Generation

1. **Run QC filtering on the original data:**

   ```bash
   python qc_before_simulation.py
   ```

   This script:

   - Loads the original VCF
   - Computes QC metrics: heterozygosity (H_obs), F-score, IBS-score
   - Applies IQR-based outlier filters
   - Writes `qc_passed_individuals.txt` (one sample ID per line)
   - Example: Filters 4,647 individuals down to 4,487 (removes 3.4% outliers)

2. **Generate hauls using QC-passed individuals:**

   ```bash
   python generate_simulated_hauls.py
   ```

   The script will automatically:

   - Detect `qc_passed_individuals.txt` if it exists
   - Print: "Loading QC-passed individuals..."
   - Use only those individuals in hauls
   - Ensure simulated hauls never contain outliers

3. **Verify all haul individuals are QC-passed:**

   ```bash
   python verify_qc_filtering.py
   ```

   This confirms 100% of individuals in hauls pass QC ✓

### Without QC Filtering

If you skip the QC step, `generate_simulated_hauls.py` will:

- Not find `qc_passed_individuals.txt`
- Use all available individuals (backward compatible)
- Print: "Using all available individuals for simulated hauls"

**Recommendation**: Run QC filtering for test/validation data (more realistic), but you can skip it if you prefer to test with raw data.

## How to Use in the Pipeline

### Option 1: Use with `main_simulation_motor.py`

1. Copy metadata file to simulations directory:

   ```bash
   cp simulated_hauls_metadata.txt ../simulations/
   ```

2. Run the pipeline:

   ```bash
   cd ../simulations
   source ../.venv/bin/activate
   python main_simulation_motor.py
   ```

3. When asked for a VCF file, provide: `Bioinformatics_Course_2025_Herring_Sample_Subset.vcf`

4. When asked for metadata, provide: `simulated_hauls_metadata.txt`

5. **When asked to apply QC filters:**

   - If you ran `qc_before_simulation.py`: Answer **`no`** to all QC filters
     - Reason: Individuals are already QC-filtered, pipeline QC would be redundant
   - If you skipped QC: Answer **`yes`** to apply filters
     - Reason: Allows pipeline to remove outliers

6. The pipeline will:
   - Load the original VCF
   - Read the metadata file
   - Automatically extract only the simulated individuals
   - Apply QC filters (if you chose `yes`)
   - Build a reference PCA

### Option 2: Use with `main_pca_mixes_experiments.py`

1. Generate reference PCA from real data (using `main_simulation_motor.py`)
2. Save `GM_all_after_QC.npz`
3. Run:
   ```bash
   python main_pca_mixes_experiments.py
   ```
4. The script will let you load the reference and project these simulated hauls into PCA space
5. Compare the true proportions (from `haul_proportions.txt`) with the pipeline's classification

## Validation

To check if the pipeline works correctly:

1. **Accuracy by proportion**: Do hauls with the same known proportion cluster together in PCA space?
2. **Classification accuracy**: Does the rule-based classifier (from `classification.py`) correctly assign population percentages?
3. **Robustness**: Do the 10 replicates of each proportion show consistent behavior despite different random individuals?

## Metadata Column Reference

### `simulated_hauls_metadata.txt`

- **sample_id**: Individual fish ID from VCF (e.g., `Gav17_001.CEL`)
- **haul_id**: Simulated haul ID (e.g., `haul_0001`)

### `haul_proportions.txt`

- **haul_id**: Simulated haul ID
- **proportion_name**: Human-readable proportion string (e.g., `50A_0N_0C_50S`)
- **Autumn\_%**, **North\_%**, **Central\_%**, **South\_%**: Expected percentages
- **Actual_A_count**, **Actual_N_count**, **Actual_C_count**, **Actual_S_count**: Actual individual counts (may differ slightly from percentages due to rounding)

## Scripts

### `qc_before_simulation.py` (Optional)

Applies QC filters to the original VCF before haul generation.

**What it does:**

1. Loads the original VCF
2. Computes QC metrics for each individual:
   - Heterozygosity (H_obs)
   - F-score (Hardy-Weinberg)
   - IBS-score (Identity-by-state)
3. Applies IQR-based outlier filters
4. Saves `qc_passed_individuals.txt` (list of QC-passed sample IDs)

**Usage:**

```bash
python qc_before_simulation.py
```

**Output:**

- `qc_passed_individuals.txt`: One sample ID per line

**Impact:**

- Reduces dataset from ~4,647 to ~4,487 individuals (removes ~3.4% outliers)
- `generate_simulated_hauls.py` will automatically use this list

### `generate_simulated_hauls.py`

Generates the simulated hauls by:

1. Loading original metadata and sample-to-population mapping
2. (Optional) Loading QC-passed individuals if `qc_passed_individuals.txt` exists
3. Defining desired proportions
4. Randomly sampling individuals from each population
5. Creating 10 replicates per proportion
6. Writing output metadata files

**Usage:**

```bash
python generate_simulated_hauls.py
```

**Behavior:**

- If `qc_passed_individuals.txt` exists: Uses only QC-passed individuals
- If file missing: Uses all available individuals

### `create_simulated_metadata.py`

Creates extended metadata files that map individuals to hauls and proportions.

**Usage:**

```bash
python create_simulated_metadata.py
```

### `verify_qc_filtering.py` (Verification)

Verifies that all individuals in simulated hauls passed QC.

**Usage:**

```bash
python verify_qc_filtering.py
```

**Output:**

- Reports if all haul individuals are in the QC-passed set
- Confirms ground truth proportions are accurate

## Customization

To create different proportions, edit `generate_simulated_hauls.py` and modify the `proportions_list`:

```python
proportions_list = [
    {"Autumn": 50, "North": 0, "Central": 0, "South": 50},
    {"Autumn": 60, "North": 40, "Central": 0, "South": 0},
    # Add more...
]
```

Then rerun the generation script.

## Notes

- **Sampling with replacement**: If a proportion requires more individuals from a population than available, sampling is done with replacement
- **Deterministic**: Scripts use `seed=42` for reproducibility
- **Rounding**: Due to integer counts, actual counts may differ slightly from expected percentages
- **All 4 populations**: When a population has 0% in a proportion, no individuals are sampled from it

## Questions or Issues?

The metadata files are straightforward TSV files that can be opened in any text editor or spreadsheet software. The VCF follows standard VCF4.2 format.
